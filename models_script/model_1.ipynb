{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from keras_metrics import precision\n",
    "from sklearn.model_selection import cross_validate\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_metrics import precision\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytujemy poprzednio utworzone zbiory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../data/cleaned_data.csv', index_col=0)\n",
    "y = pd.read_csv('../data/labels.csv', header = None)\n",
    "\n",
    "X_test = pd.read_csv('../data/X_test.csv', index_col=0)\n",
    "X_train = pd.read_csv('../data/X_train.csv', index_col=0)\n",
    "X_train_std = pd.read_csv('../data/X_train_std.csv', index_col=0)\n",
    "X_test_std = pd.read_csv('../data/X_test_std.csv', index_col=0)\n",
    "y_train = pd.read_csv('../data/y_train.csv', index_col=0)\n",
    "y_test = pd.read_csv('../data/y_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbuduję przykładową sieć, która składa się z warstwy wejściowej, jednej warstwy ukrytej i  warstwy wyjściowej.\n",
    "Kompilujemy model przy użyciu \n",
    "\n",
    "loss_function='binary_crossentropy';\n",
    "\n",
    "optimizer='Adam'.\n",
    "\n",
    "\n",
    "Naszą główną metryką będzie **precyzja** oznaczająca procent osób prawidłowie określonych jako zagrożone odejściem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pierwsze podejście do modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6700 samples, validate on 3300 samples\n",
      "Epoch 1/3\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.4297 - precision: 0.6413662237872171 - acc: 0.8185 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 2/3\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.3717 - precision: 0.7299465239665848 - acc: 0.8476 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 3/3\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.3549 - precision: 0.7599999999019356 - acc: 0.8564 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "3300/3300 [==============================] - 0s 17us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3576833701494968, 0.7412790695519539, 0.8466666666666667]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(11, activation='relu', input_shape=(10,)))\n",
    " \n",
    "model.add(Dense(121, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[precision(),'accuracy'])\n",
    "                   \n",
    "model.fit(X_train_std, y_train,epochs=3, batch_size=1, verbose=1, validation_data=(X_test,y_test))\n",
    "\n",
    "model.evaluate(X_test_std,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprawdźmy skuteczność naszej predykcji raportem klasyfikacyjnym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      2628\n",
      "           1       0.74      0.38      0.50       672\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      3300\n",
      "   macro avg       0.80      0.67      0.71      3300\n",
      "weighted avg       0.83      0.85      0.83      3300\n",
      "\n",
      "0.8589309878213802\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test_std)\n",
    "report = classification_report(y_test,y_pred)\n",
    "report1 = classification_report(y_test,y_pred,output_dict=True)\n",
    "print(report)\n",
    "print(report1['0']['precision'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdźmy, jak prezentują się wyniki w zależności od liczby neuronów w warstwie ukrytej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6700 samples, validate on 3300 samples\n",
      "Epoch 1/5\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.4367 - precision: 0.6375321335122026 - acc: 0.8122 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 2/5\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.3706 - precision: 0.7182910546437529 - acc: 0.8451 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 3/5\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.3585 - precision: 0.7308641974406341 - acc: 0.8521 - val_loss: 3.2933 - val_precision: 0.0000e+00 - val_acc: 0.7955\n",
      "Epoch 4/5\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.3517 - precision: 0.7421686746093773 - acc: 0.8563 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 5/5\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.3488 - precision: 0.7724935731654893 - acc: 0.8596 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Zakończono trenowanie modelu z 10 węzłami.\n",
      "3300/3300 [==============================] - 0s 15us/step\n",
      "Train on 6700 samples, validate on 3300 samples\n",
      "Epoch 1/5\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.4323 - precision: 0.6910828023276807 - acc: 0.8142 - val_loss: 5.1013 - val_precision: 0.2401 - val_acc: 0.6815\n",
      "Epoch 2/5\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.3625 - precision: 0.7578347577268042 - acc: 0.8503 - val_loss: 8.6512 - val_precision: 0.2391 - val_acc: 0.4579\n",
      "Epoch 3/5\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.3480 - precision: 0.7603092782525375 - acc: 0.8566 - val_loss: 12.6436 - val_precision: 0.2043 - val_acc: 0.2067\n",
      "Epoch 4/5\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.3451 - precision: 0.7558859974280191 - acc: 0.8579 - val_loss: 6.1515 - val_precision: 0.2228 - val_acc: 0.6155\n",
      "Epoch 5/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3421 - precision: 0.7705521471447175 - acc: 0.8621 - val_loss: 6.7833 - val_precision: 0.2255 - val_acc: 0.5758\n",
      "Zakończono trenowanie modelu z 30 węzłami.\n",
      "3300/3300 [==============================] - 0s 14us/step\n",
      "Train on 6700 samples, validate on 3300 samples\n",
      "Epoch 1/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.4384 - precision: 0.6564705880808305 - acc: 0.8161 - val_loss: 3.8357 - val_precision: 0.2717 - val_acc: 0.7612\n",
      "Epoch 2/5\n",
      "6700/6700 [==============================] - 9s 1ms/step - loss: 0.3751 - precision: 0.7527932959842468 - acc: 0.8503 - val_loss: 5.2820 - val_precision: 0.2367 - val_acc: 0.6703\n",
      "Epoch 3/5\n",
      "6700/6700 [==============================] - 9s 1ms/step - loss: 0.3531 - precision: 0.7631241996462069 - acc: 0.8576 - val_loss: 6.3754 - val_precision: 0.2330 - val_acc: 0.6012\n",
      "Epoch 4/5\n",
      "6700/6700 [==============================] - 9s 1ms/step - loss: 0.3472 - precision: 0.773946360054413 - acc: 0.8603 - val_loss: 8.2327 - val_precision: 0.2407 - val_acc: 0.4842\n",
      "Epoch 5/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3433 - precision: 0.7639060567658954 - acc: 0.8600 - val_loss: 7.6688 - val_precision: 0.2384 - val_acc: 0.5197\n",
      "Zakończono trenowanie modelu z 50 węzłami.\n",
      "3300/3300 [==============================] - 0s 15us/step\n",
      "Train on 6700 samples, validate on 3300 samples\n",
      "Epoch 1/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.4359 - precision: 0.668407310530442 - acc: 0.8155 - val_loss: 7.4592 - val_precision: 0.1448 - val_acc: 0.5333\n",
      "Epoch 2/5\n",
      "6700/6700 [==============================] - 7s 1ms/step - loss: 0.3741 - precision: 0.7161981257408035 - acc: 0.8445 - val_loss: 12.6511 - val_precision: 0.2040 - val_acc: 0.2064\n",
      "Epoch 3/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3561 - precision: 0.752269779409563 - acc: 0.8543 - val_loss: 12.6718 - val_precision: 0.2039 - val_acc: 0.2052\n",
      "Epoch 4/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3505 - precision: 0.7620865138979535 - acc: 0.8578 - val_loss: 12.5934 - val_precision: 0.2043 - val_acc: 0.2097\n",
      "Epoch 5/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3469 - precision: 0.7711757268304456 - acc: 0.8603 - val_loss: 12.6669 - val_precision: 0.2040 - val_acc: 0.2055\n",
      "Zakończono trenowanie modelu z 70 węzłami.\n",
      "3300/3300 [==============================] - 0s 17us/step\n",
      "Train on 6700 samples, validate on 3300 samples\n",
      "Epoch 1/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.4150 - precision: 0.6605657236837661 - acc: 0.8251 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 2/5\n",
      "6700/6700 [==============================] - 9s 1ms/step - loss: 0.3644 - precision: 0.7274969172962397 - acc: 0.8513 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 3/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3531 - precision: 0.762437810850443 - acc: 0.8593 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 4/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3481 - precision: 0.7633872975388061 - acc: 0.8594 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 5/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3440 - precision: 0.7563946405899642 - acc: 0.8591 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Zakończono trenowanie modelu z 90 węzłami.\n",
      "3300/3300 [==============================] - 0s 19us/step\n",
      "Train on 6700 samples, validate on 3300 samples\n",
      "Epoch 1/5\n",
      "6700/6700 [==============================] - 9s 1ms/step - loss: 0.4066 - precision: 0.6874999998925782 - acc: 0.8321 - val_loss: 3.2824 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 2/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3630 - precision: 0.7397435896487509 - acc: 0.8521 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 3/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3554 - precision: 0.7493606137149156 - acc: 0.8545 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 4/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3520 - precision: 0.750316856685638 - acc: 0.8552 - val_loss: 3.2822 - val_precision: 0.0000e+00 - val_acc: 0.7964\n",
      "Epoch 5/5\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3500 - precision: 0.7748091602067673 - acc: 0.8607 - val_loss: 3.3181 - val_precision: 0.0000e+00 - val_acc: 0.7939\n",
      "Zakończono trenowanie modelu z 110 węzłami.\n",
      "3300/3300 [==============================] - 0s 17us/step\n",
      "{50: [0.8727779714186128, 0.7122969837587007], 110: [0.8626580116159891, 0.7238605898123325], 70: [0.8698988489710499, 0.6905311778290993], 10: [0.8610169491525423, 0.7485714285714286], 90: [0.8605200945626478, 0.7640117994100295], 30: [0.8709342560553633, 0.7292682926829268]}\n"
     ]
    }
   ],
   "source": [
    "nodes = [10, 30, 50, 70, 90, 110]\n",
    "wyniki = {}\n",
    "for i in nodes:\n",
    "    model = 0\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(11, activation='relu', input_shape=(10,)))\n",
    "\n",
    "    model.add(Dense(i, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[precision(), 'accuracy'])\n",
    "\n",
    "    model.fit(X_train_std, y_train, epochs=5, batch_size=1, verbose=1, validation_data=(X_test, y_test))\n",
    "    print(\"Zakończono trenowanie modelu z {0} węzłami.\".format(i))\n",
    "    model.evaluate(X_test_std, y_test)\n",
    "    y_pred = model.predict_classes(X_test_std)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    wyniki.update({i: [report['0']['precision'], report['1']['precision']]})\n",
    "\n",
    "print(wyniki)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wybieramy model z 90 węzłami - dał najlepsze wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
      "Train on 6700 samples, validate on 3300 samples\n",
      "Epoch 1/30\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.4401 - precision: 0.5113 - accuracy: 0.8161 - val_loss: 4952.8738 - val_precision: 0.0000e+00 - val_accuracy: 0.7964\n",
      "Epoch 2/30\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3944 - precision: 0.6957 - accuracy: 0.8379 - val_loss: 8124.6009 - val_precision: 0.0000e+00 - val_accuracy: 0.7964\n",
      "Epoch 3/30\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3835 - precision: 0.7191 - accuracy: 0.8461 - val_loss: 4179.3550 - val_precision: 0.2710 - val_accuracy: 0.7048\n",
      "Epoch 4/30\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3729 - precision: 0.7816 - accuracy: 0.8466 - val_loss: 4503.9204 - val_precision: 0.2476 - val_accuracy: 0.5845\n",
      "Epoch 5/30\n",
      "6700/6700 [==============================] - 8s 1ms/step - loss: 0.3662 - precision: 0.7778 - accuracy: 0.8510 - val_loss: 10013.8224 - val_precision: 0.2446 - val_accuracy: 0.4600\n",
      "3300/3300 [==============================] - 0s 15us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91      2628\n",
      "           1       0.78      0.35      0.48       672\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      3300\n",
      "   macro avg       0.82      0.66      0.70      3300\n",
      "weighted avg       0.84      0.85      0.82      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='model_1')\n",
    "\n",
    "model.add(Dense(10, activation='relu', input_shape=(10,)))\n",
    "model.add(Dropout(0.1, ))\n",
    "\n",
    "model.add(Dense(90, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[precision(), 'accuracy'])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "model.fit(X_train_std, y_train, epochs=30, batch_size=1, verbose=1, validation_data=(X_test, y_test),\n",
    "          callbacks=[early_stopping_monitor])\n",
    "\n",
    "model.evaluate(X_test_std, y_test)\n",
    "y_pred = model.predict_classes(X_test_std)\n",
    "report = classification_report(y_test, y_pred)\n",
    "report1 = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zapisujemy wytrenowany model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../saved_models/model_1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autor: Tomasz Sołtysiak"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
